# Conversational Agent with Blenderbot Model

This project demonstrates the usage of Facebook's Blenderbot model, a pre-trained conversational AI model, available on [Hugging Face](https://huggingface.co/transformers/model_doc/blenderbot.html)

The code allows you to build a conversational agent using the Blenderbot model.

## Code Explanation

- **Imports**: The code imports the necessary modules from the Transformers library: BlenderbotTokenizer and BlenderbotForConditionalGeneration. These modules are specifically designed for working with the Blenderbot model.

- **Model and Tokenizer Setup**: The code defines the model name as `'facebook/blenderbot-400M-distill'`, which refers to the pre-trained Blenderbot model provided by Facebook with 400 million parameters. The BlenderbotTokenizer is then initialized using the specified model name, and the BlenderbotForConditionalGeneration model is loaded with the same model name. This step downloads the model and sets it up for use.

- **Define an Utterance**: An utterance is defined as a string containing the input text that you want to generate a response to. In the example code, the utterance is set to `"My name is hello, I like world"`.

- **Tokenization**: The tokenizer object is used to tokenize the utterance. The tokenizer converts the input text into a format that the model can understand. The tokenizer function is called with the utterance as the input, and return_tensors="pt" specifies that the tokenized inputs should be returned as PyTorch tensors.

- **Generate Model Results**: The model object is used to generate results based on the tokenized inputs. The generate method of the model is called with **inputs, which unpacks the tokenized inputs as keyword arguments. This step generates a response based on the given utterance.

- **Decoding**: The generated result is encoded and needs to be decoded to obtain the text response. The decode method of the tokenizer is used to decode the result. In this case, result[0] refers to the first generated result.

- **Print Generated Response**: Finally, the generated response is printed to the console using print. The response represents the output generated by the Blenderbot model in response to the provided utterance.


## Requirements

- Python 3+
- Transformers library

## Installation

1. Clone the repository:

   ```shell
   git clone https://github.com/christianadebambo/blender-chat-bot-AI.git
   ```
   
## Usage

```cd blender-chat-bot-AI```

```python blender_bot.py```
